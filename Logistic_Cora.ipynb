{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.10 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "b7f1b95351681b540155715b28096180c8e313e57d5a257fa2998b8b35cfe1c7"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       Unnamed: 0          country       language  world_gross_income\n",
       "0              79           Russia        Russian            144968.0\n",
       "1             165          Germany         German              8811.0\n",
       "2             222              USA        English            772155.0\n",
       "3             245              USA        English           9183673.0\n",
       "4             251              USA        English             26916.0\n",
       "...           ...              ...            ...                 ...\n",
       "30851       85847            India      Malayalam              4791.0\n",
       "30852       85850  France, Belgium         French           3507171.0\n",
       "30853       85851      Netherlands  German, Dutch           7299062.0\n",
       "30854       85853           Turkey        Turkish              2833.0\n",
       "30855       85854            Spain        Catalan             59794.0\n",
       "\n",
       "[30856 rows x 4 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>country</th>\n      <th>language</th>\n      <th>world_gross_income</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>79</td>\n      <td>Russia</td>\n      <td>Russian</td>\n      <td>144968.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>165</td>\n      <td>Germany</td>\n      <td>German</td>\n      <td>8811.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>222</td>\n      <td>USA</td>\n      <td>English</td>\n      <td>772155.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>245</td>\n      <td>USA</td>\n      <td>English</td>\n      <td>9183673.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>251</td>\n      <td>USA</td>\n      <td>English</td>\n      <td>26916.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>30851</th>\n      <td>85847</td>\n      <td>India</td>\n      <td>Malayalam</td>\n      <td>4791.0</td>\n    </tr>\n    <tr>\n      <th>30852</th>\n      <td>85850</td>\n      <td>France, Belgium</td>\n      <td>French</td>\n      <td>3507171.0</td>\n    </tr>\n    <tr>\n      <th>30853</th>\n      <td>85851</td>\n      <td>Netherlands</td>\n      <td>German, Dutch</td>\n      <td>7299062.0</td>\n    </tr>\n    <tr>\n      <th>30854</th>\n      <td>85853</td>\n      <td>Turkey</td>\n      <td>Turkish</td>\n      <td>2833.0</td>\n    </tr>\n    <tr>\n      <th>30855</th>\n      <td>85854</td>\n      <td>Spain</td>\n      <td>Catalan</td>\n      <td>59794.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>30856 rows × 4 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "ml_movies=pd.read_csv(\"Resource/IMDB_cora.csv\")\n",
    "ml_movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "               country       language  world_gross_income\n",
       "0               Russia        Russian            144968.0\n",
       "1              Germany         German              8811.0\n",
       "2                  USA        English            772155.0\n",
       "3                  USA        English           9183673.0\n",
       "4                  USA        English             26916.0\n",
       "...                ...            ...                 ...\n",
       "30851            India      Malayalam              4791.0\n",
       "30852  France, Belgium         French           3507171.0\n",
       "30853      Netherlands  German, Dutch           7299062.0\n",
       "30854           Turkey        Turkish              2833.0\n",
       "30855            Spain        Catalan             59794.0\n",
       "\n",
       "[30856 rows x 3 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>country</th>\n      <th>language</th>\n      <th>world_gross_income</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Russia</td>\n      <td>Russian</td>\n      <td>144968.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Germany</td>\n      <td>German</td>\n      <td>8811.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>USA</td>\n      <td>English</td>\n      <td>772155.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>USA</td>\n      <td>English</td>\n      <td>9183673.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>USA</td>\n      <td>English</td>\n      <td>26916.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>30851</th>\n      <td>India</td>\n      <td>Malayalam</td>\n      <td>4791.0</td>\n    </tr>\n    <tr>\n      <th>30852</th>\n      <td>France, Belgium</td>\n      <td>French</td>\n      <td>3507171.0</td>\n    </tr>\n    <tr>\n      <th>30853</th>\n      <td>Netherlands</td>\n      <td>German, Dutch</td>\n      <td>7299062.0</td>\n    </tr>\n    <tr>\n      <th>30854</th>\n      <td>Turkey</td>\n      <td>Turkish</td>\n      <td>2833.0</td>\n    </tr>\n    <tr>\n      <th>30855</th>\n      <td>Spain</td>\n      <td>Catalan</td>\n      <td>59794.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>30856 rows × 3 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "ml_movies= ml_movies.drop(\"Unnamed: 0\", axis=1)\n",
    "ml_movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array(['Russian', 'German', 'English', ...,\n",
       "       'Thai, English, Mandarin, Cantonese', 'English, Finnish, Mandarin',\n",
       "       'German, Dutch'], dtype=object)"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "ml_movies[\"language\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "               country    language  world_gross_income\n0               Russia  NonEnglish            144968.0\n1              Germany  NonEnglish              8811.0\n2                  USA     English            772155.0\n3                  USA     English           9183673.0\n4                  USA     English             26916.0\n...                ...         ...                 ...\n30851            India  NonEnglish              4791.0\n30852  France, Belgium  NonEnglish           3507171.0\n30853      Netherlands  NonEnglish           7299062.0\n30854           Turkey  NonEnglish              2833.0\n30855            Spain  NonEnglish             59794.0\n\n[30856 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "#Create function to replace labels\n",
    "English = [\"English\",\"english\",\"English,None\"]\n",
    "def clean(response):\n",
    "    if response.lower().rstrip() in English:\n",
    "        return \"English\"\n",
    "    else:\n",
    "        return \"NonEnglish\"\n",
    "ml_movies[\"language\"] = ml_movies[\"language\"].apply(lambda x: clean(x))\n",
    "print(ml_movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0        NonEnglish\n1        NonEnglish\n2           English\n3           English\n4           English\n            ...    \n30851    NonEnglish\n30852    NonEnglish\n30853    NonEnglish\n30854    NonEnglish\n30855    NonEnglish\nName: language, Length: 30856, dtype: object [[1.449680e+05]\n [8.811000e+03]\n [7.721550e+05]\n ...\n [7.299062e+06]\n [2.833000e+03]\n [5.979400e+04]]\n"
     ]
    }
   ],
   "source": [
    "#Set up definition for X and y and reshape the data\n",
    "X=ml_movies[\"language\"]\n",
    "y=ml_movies[\"world_gross_income\"].values.reshape(-1,1)\n",
    "print(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array(['English', 'NonEnglish'], dtype=object)"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "# Apply label encoding to categorize the language as being English or non-English\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "data = X.copy()\n",
    "label_encoder.fit(data)\n",
    "label_encoder.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transform the data using label encoding\n",
    "label_encoder.transform(data)\n",
    "X = pd.get_dummies(X)\n",
    "X = X.to_numpy()\n",
    "X= X.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [61712, 30856]",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-b25efce067bc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Split the data into training and testing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/envs/dviz_ml/lib/python3.6/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[1;32m   2170\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"At least one array required as input\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2172\u001b[0;31m     \u001b[0marrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2174\u001b[0m     \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/dviz_ml/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mindexable\u001b[0;34m(*iterables)\u001b[0m\n\u001b[1;32m    297\u001b[0m     \"\"\"\n\u001b[1;32m    298\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_make_indexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterables\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 299\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    300\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/dviz_ml/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    261\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0;32m--> 263\u001b[0;31m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [61712, 30856]"
     ]
    }
   ],
   "source": [
    "#Split the data into training and testing\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a StandardScaler model\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "X_scaler = StandardScaler().fit(X_train)\n",
    "y_scaler = StandardScaler().fit(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transform training and testing data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "y_train_scaled = y_scaler.transform(y_train)\n",
    "y_test_scaled = y_scaler.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.fit(X_train_scaled, y_train_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Training Data Score: {classifier.score(X_train_scaled, y_train_scaled)}\")\n",
    "print(f\"Testing Data Score: {classifier.score(X_test_scaled, y_test_scaled)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = classifier.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({\"Prediction\": predictions, \"Actual\": y_test_scaled}).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Conclusion: Logistic Regression did not work, so decided to use tensorflow to create an analysis of existing data to make a prediction, which is that English language movies are the highest grossing movies. "
   ]
  }
 ]
}